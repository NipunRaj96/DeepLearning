{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NipunRaj96/DeepLearning/blob/main/bigram_nextWordPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict\n",
        "import random\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eog7wpv7Jjb_",
        "outputId": "6352b1b8-7ff4-44dc-cd29-591fb2d0a973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text= \"\"\"Hello, how are you? I am doing well.\n",
        "How are you today? I am good.\n",
        "How are you? I am unwell.\"\"\"\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6kHScC8uqef",
        "outputId": "5c825319-9e1a-4688-c63e-04a90693d09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, how are you? I am doing well.\n",
            "How are you today? I am good.\n",
            "How are you? I am unwell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text= text.lower()\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lb2uiG4EsIid",
        "outputId": "7652f907-0c52-4f09-f873-66c3ff66d0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello, how are you? i am doing well.\\nhow are you today? i am good.\\nhow are you? i am unwell.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(text) # Tokenizes the input text into lowercase words.\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cfwPWUEryGv",
        "outputId": "f29c7b1d-a60d-4ec0-b7d8-7179549debf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', ',', 'how', 'are', 'you', '?', 'i', 'am', 'doing', 'well', '.', 'how', 'are', 'you', 'today', '?', 'i', 'am', 'good', '.', 'how', 'are', 'you', '?', 'i', 'am', 'unwell', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=2\n",
        "ngrams_list = list(ngrams(tokens, n)) # 2. Generates a list of n-grams (e.g., bigrams) from the tokens.\n",
        "print(ngrams_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gck8K8F5VHWT",
        "outputId": "03fed852-af00-4ff0-a919-9bd94b89b01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hello', ','), (',', 'how'), ('how', 'are'), ('are', 'you'), ('you', '?'), ('?', 'i'), ('i', 'am'), ('am', 'doing'), ('doing', 'well'), ('well', '.'), ('.', 'how'), ('how', 'are'), ('are', 'you'), ('you', 'today'), ('today', '?'), ('?', 'i'), ('i', 'am'), ('am', 'good'), ('good', '.'), ('.', 'how'), ('how', 'are'), ('are', 'you'), ('you', '?'), ('?', 'i'), ('i', 'am'), ('am', 'unwell'), ('unwell', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nested dictionary initialization using defaultdict\n",
        "model = defaultdict(lambda: defaultdict(int))"
      ],
      "metadata": {
        "id": "rtxAvVX4vqVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l= ['hello', 'Hello', 'hi', 'hello', 'bye']\n",
        "d= defaultdict(int)\n",
        "for word in l:\n",
        "  d[word]+=1\n",
        "d"
      ],
      "metadata": {
        "id": "-1mjtAgPw1TJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d05b59-5929-491a-ad47-2953e5bf02d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int, {'hello': 2, 'Hello': 1, 'hi': 1, 'bye': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a= ['hello', 'hello', 'hi', 'are', 'you', 'you']\n",
        "b= defaultdict(int)\n",
        "for word in a:\n",
        "  b[word]+=1\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sFlwo1MxqZR",
        "outputId": "c77b2841-fa8c-4344-d4d9-50ce490ff189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int, {'hello': 2, 'hi': 1, 'are': 1, 'you': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ngrams_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqIt4oKdy02n",
        "outputId": "6aa6cc1f-1488-4351-fe65-d122f087fb1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hello', ','), (',', 'how'), ('how', 'are'), ('are', 'you'), ('you', '?'), ('?', 'i'), ('i', 'am'), ('am', 'doing'), ('doing', 'well'), ('well', '.'), ('.', 'how'), ('how', 'are'), ('are', 'you'), ('you', 'today'), ('today', '?'), ('?', 'i'), ('i', 'am'), ('am', 'good'), ('good', '.'), ('.', 'how'), ('how', 'are'), ('are', 'you'), ('you', '?'), ('?', 'i'), ('i', 'am'), ('am', 'unwell'), ('unwell', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "from collections import defaultdict\n",
        "bigram_model = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "## Add a bigram ('hello', 'world')\n",
        "bigram_model['hello']['world'] += 1\n",
        "\n",
        "What Happens Internally?\n",
        "# bigram_model['hello'] does not exist → So, it creates a new defaultdict(int).\n",
        "\n",
        "bigram_model = {'hello': defaultdict(int)}\n",
        "\n",
        "bigram_model['hello']['world'] does not exist →\n",
        "So, it initializes to 0 and increments by 1\n",
        "\n",
        "bigram_model['hello']['world'] = 1\n",
        "\n",
        "--- without using defaultdict---\n",
        "\n",
        "bigram_model = {}\n",
        "This would raise KeyError because 'hello' is not initialized\n",
        "\n",
        "bigram_model['hello']['world'] += 1\n",
        "\n",
        "Instead, we’d need to manually check and initialize:\n",
        "\n",
        "if 'hello' not in bigram_model:\n",
        "    bigram_model['hello'] = {}\n",
        "\n",
        "if 'world' not in bigram_model['hello']:\n",
        "    bigram_model['hello']['world'] = 0\n",
        "\n",
        "bigram_model['hello']['world'] += 1\n",
        "\n",
        "Using defaultdict eliminates this manual initialization, making the code cleaner.\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ilCQd35H0WNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ngrams_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkYLCURI2QkZ",
        "outputId": "f10491e9-1fe1-4166-c501-f702c4f24f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hello', ','), (',', 'how'), ('how', 'are'), ('are', 'you'), ('you', '?'), ('?', 'i'), ('i', 'am'), ('am', 'doing'), ('doing', 'well'), ('well', '.'), ('.', 'how'), ('how', 'are'), ('are', 'you'), ('you', 'today'), ('today', '?'), ('?', 'i'), ('i', 'am'), ('am', 'good'), ('good', '.'), ('.', 'how'), ('how', 'are'), ('are', 'you'), ('you', '?'), ('?', 'i'), ('i', 'am'), ('am', 'unwell'), ('unwell', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= defaultdict(lambda: defaultdict(int))\n",
        "for pair in ngrams_list:\n",
        "  history= pair[0:-1]\n",
        "  pred= pair[-1]\n",
        "  model[history][pred]+=1\n",
        "\n",
        "model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBxmwJddWp5I",
        "outputId": "fa7009d3-589b-44be-dec0-83808378507d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>()>,\n",
              "            {('hello',): defaultdict(int, {',': 1}),\n",
              "             (',',): defaultdict(int, {'how': 1}),\n",
              "             ('how',): defaultdict(int, {'are': 3}),\n",
              "             ('are',): defaultdict(int, {'you': 3}),\n",
              "             ('you',): defaultdict(int, {'?': 2, 'today': 1}),\n",
              "             ('?',): defaultdict(int, {'i': 3}),\n",
              "             ('i',): defaultdict(int, {'am': 3}),\n",
              "             ('am',): defaultdict(int, {'doing': 1, 'good': 1, 'unwell': 1}),\n",
              "             ('doing',): defaultdict(int, {'well': 1}),\n",
              "             ('well',): defaultdict(int, {'.': 1}),\n",
              "             ('.',): defaultdict(int, {'how': 2}),\n",
              "             ('today',): defaultdict(int, {'?': 1}),\n",
              "             ('good',): defaultdict(int, {'.': 1}),\n",
              "             ('unwell',): defaultdict(int, {'.': 1})})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The lambda function is used to dynamically create nested dictionaries when a new key is accessed\n",
        "#  for the first time\n",
        "model= defaultdict(lambda: defaultdict(int))\n",
        "for pair in ngrams_list:\n",
        "  history= pair[:-1]\n",
        "  predictions= pair[-1]\n",
        "  model[history][predictions]+= 1"
      ],
      "metadata": {
        "id": "pIBYmUaIw1nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model with standard dictionaries\n",
        "for history, predictions in model.items():\n",
        "    print(history, dict(predictions)) #Convert the defaultdict to a regular dict."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFrWXGOIwgiA",
        "outputId": "81c573a6-c5c7-4647-baa8-494fe71e12d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('hello',) {',': 1}\n",
            "(',',) {'how': 1}\n",
            "('how',) {'are': 3}\n",
            "('are',) {'you': 3}\n",
            "('you',) {'?': 2, 'today': 1}\n",
            "('?',) {'i': 3}\n",
            "('i',) {'am': 3}\n",
            "('am',) {'doing': 1, 'good': 1, 'unwell': 1}\n",
            "('doing',) {'well': 1}\n",
            "('well',) {'.': 1}\n",
            "('.',) {'how': 2}\n",
            "('today',) {'?': 1}\n",
            "('good',) {'.': 1}\n",
            "('unwell',) {'.': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in model.items():\n",
        "  count= float(sum(v.values()))\n",
        "  for ke, va in v.items():\n",
        "    model[k][ke] = va / count\n",
        "\n",
        "# Print the model with standard dictionaries\n",
        "for history, predictions in model.items():\n",
        "    print(history, dict(predictions)) #Convert the defaultdict to a regular dict."
      ],
      "metadata": {
        "id": "zCisjiN83zD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model[('you',)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG4Nsy--RVr_",
        "outputId": "2d47dbd7-eac6-4785-90e8-ce2d945a9531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int, {'?': 0.6666666666666666, 'today': 0.3333333333333333})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "history = ['you']\n",
        "history = tuple(history) # Converts the history (list) to a tuple (immutable, used as dictionary key).\n",
        "if history in model: # Checks if the history exists in the model.\n",
        "      probabilities = model[history] # Retrieves the probabilities of words following the history.\n",
        "      words = list(probabilities.keys()) # Extracts the list of words from the probabilities dictionary.\n",
        "      probs = list(probabilities.values()) # Extracts the list of words from the probabilities dictionary.\n",
        "      random.choices(words, weights=probs)[0]\n",
        "else:\n",
        "  print(\" \")\n",
        "\n"
      ],
      "metadata": {
        "id": "Z06Z6WCZRKXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIsCFvP99M_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bigram_model(text, n=2):\n",
        "    \"\"\"\n",
        "    Trains a bigram model from the given text.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): Input text.\n",
        "        n (int): N-gram size (default=2 for bigrams).\n",
        "\n",
        "    Returns:\n",
        "        model (defaultdict): Nested dictionary with word probabilities.\n",
        "    \"\"\"\n",
        "    # Tokenization\n",
        "    tokens = nltk.word_tokenize(text.lower())  # Convert text to lowercase\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "\n",
        "    # Generate N-grams (bigrams in this case)\n",
        "    ngrams_list = list(ngrams(tokens, n))\n",
        "    print(f\"N-Grams: {ngrams_list}\")\n",
        "\n",
        "    # Initialize nested dictionary\n",
        "    model = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # Count occurrences of word pairs\n",
        "    for pair in ngrams_list:\n",
        "        history = pair[:-1]  # First word\n",
        "        predictions = pair[-1]  # Next word\n",
        "        model[history][predictions] += 1\n",
        "\n",
        "    # Convert counts to probabilities\n",
        "    for k, v in model.items():\n",
        "        count = float(sum(v.values()))\n",
        "        for ke, va in v.items():\n",
        "            model[k][ke] = va / count  # Convert counts to probabilities\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_next_word(model, history):\n",
        "    \"\"\"\n",
        "    Predicts the next word based on the given history.\n",
        "\n",
        "    Parameters:\n",
        "        model (defaultdict): The trained bigram model.\n",
        "        history (list): List of words representing the context.\n",
        "\n",
        "    Returns:\n",
        "        str: Predicted next word or an empty string if history is unseen.\n",
        "    \"\"\"\n",
        "    history = tuple(history)  # Convert list to tuple (immutable dictionary key)\n",
        "\n",
        "    if history in model:\n",
        "        probabilities = model[history]\n",
        "        words = list(probabilities.keys())  # Possible next words\n",
        "        probs = list(probabilities.values())  # Corresponding probabilities\n",
        "        return random.choices(words, weights=probs)[0]  # Sample based on probability\n",
        "\n",
        "    return \" \"  # Return empty string if history is unseen\n",
        "\n",
        "# Sample text input\n",
        "text = \"\"\"Hello, how are you? I am doing well.\n",
        "How are you today? I am good.\n",
        "How are you? I am unwell.\"\"\"\n",
        "\n",
        "# Train the bigram model\n",
        "bigram_model = train_bigram_model(text)\n",
        "\n",
        "# Predict the next word\n",
        "history = [\"you\"]\n",
        "predicted_word = predict_next_word(bigram_model, history)\n",
        "\n",
        "print(f\"\\nGiven history: {history}, Predicted next word: {predicted_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShNAYtzD9IpL",
        "outputId": "13b46aa2-376f-4ac6-e29d-24ac2a91ec8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['hello', ',', 'how', 'are', 'you', '?', 'i', 'am', 'doing', 'well', '.', 'how', 'are', 'you', 'today', '?', 'i', 'am', 'good', '.', 'how', 'are', 'you', '?', 'i', 'am', 'unwell', '.']\n",
            "N-Grams: [('hello', ','), (',', 'how'), ('how', 'are'), ('are', 'you'), ('you', '?'), ('?', 'i'), ('i', 'am'), ('am', 'doing'), ('doing', 'well'), ('well', '.'), ('.', 'how'), ('how', 'are'), ('are', 'you'), ('you', 'today'), ('today', '?'), ('?', 'i'), ('i', 'am'), ('am', 'good'), ('good', '.'), ('.', 'how'), ('how', 'are'), ('are', 'you'), ('you', '?'), ('?', 'i'), ('i', 'am'), ('am', 'unwell'), ('unwell', '.')]\n",
            "\n",
            "Given history: ['you'], Predicted next word: ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYymabkK9I-L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}